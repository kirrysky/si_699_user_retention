{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM\n",
    "\n",
    "- Author: Wen Xin\n",
    "- Description: This file means that I use lightGBM as model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train_transfer.csv')\n",
    "test=pd.read_csv('test_transfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['last_order',\n",
    " 'active_days',\n",
    " 'w7_total_orders',\n",
    " 'log_total_orders',\n",
    " 'order_sd',\n",
    " 'lastgap',\n",
    " 'avg_gap',\n",
    " 'log_order_sd',\n",
    " 'w6_total_orders',\n",
    " 'min_gap',\n",
    " 'w7_avg_couponworth',\n",
    " 'log_lastgap',\n",
    " 'log_min_gap',\n",
    " 'order_nums',\n",
    " 'w7_max_couponworth',\n",
    " 'log_w7_max_couponworth',\n",
    " 'dummy_log_lastgap',\n",
    " 'w5_total_orders',\n",
    " 'log_avg_gap',\n",
    " 'max_gap',\n",
    " 'send2update_time_min',\n",
    " 'update2create_time_min',\n",
    " 'kitchen_royalty',\n",
    " 'dummy_log_avg_gap',\n",
    " 'log_send2update_time_min',\n",
    " 'dummy_log_min_gap',\n",
    " 'app_version_b',\n",
    " 'w6_max_couponworth',\n",
    " 'dummy_log_max_gap',\n",
    " 'w6_avg_couponworth',\n",
    " 'log_w6_max_couponworth',\n",
    " 'log_max_gap',\n",
    " 'w4_total_orders',\n",
    " 'w5_max_couponworth',\n",
    " 'w5_avg_couponworth',\n",
    " 'log_overall_time_min',\n",
    " 'overall_time_min',\n",
    " 'w3_total_orders',\n",
    " 'comment_perc',\n",
    " 'w4_max_couponworth',\n",
    " 'w4_avg_couponworth',\n",
    " 'overall_time_max',\n",
    " 'w2_total_orders',\n",
    " 'w3_max_couponworth',\n",
    " 'w1_total_orders',\n",
    " 'age',\n",
    " 'accountLength',\n",
    " 'w3_avg_couponworth',\n",
    " 'first_order',\n",
    " 'w2_max_couponworth',\n",
    " 'update2create_time_mean',\n",
    " 'w2_avg_couponworth',\n",
    " 'w1_avg_couponworth',\n",
    " 'sex',\n",
    " 'w1_max_couponworth',\n",
    " 'send2update_time_mean',\n",
    " 'update2create_time_max',\n",
    " 'last_coupon_fee',\n",
    " 'dummy_log_send2update_time_mean',\n",
    " 'log_send2update_time_mean',\n",
    " 'overall_time_mean',\n",
    " 'login_platform_b',\n",
    " 'like_num',\n",
    " 'staple_price',\n",
    " 'intime_rate',\n",
    " 'send2update_time_max',\n",
    " 'log_overall_time_mean',\n",
    " 'city_id',\n",
    " 'last_send_type',\n",
    " 'log_send2update_time_max',\n",
    " 'label',\n",
    " 'pca_1',\n",
    " 'pca_2',\n",
    " 'pca_3',\n",
    " 'pca_4',\n",
    " 'pca_5',\n",
    " 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[features]\n",
    "test=test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['label']\n",
    "X_train=train.drop(['label'],axis=1)\n",
    "y_test=test['label']\n",
    "X_test=test.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[\n",
    " 'last_send_type',\n",
    " 'city_id',\n",
    " 'sex',\n",
    " 'age',\n",
    " 'login_platform_b',\n",
    " 'app_version_b',\n",
    " 'age_na',\n",
    " 'lastgap_na',\n",
    " 'avg_gap_na',\n",
    " 'min_gap_na',\n",
    " 'max_gap_na',\n",
    " 'overall_time_mean_na',\n",
    " 'update2create_time_mean_na',\n",
    " 'send2update_time_mean_na',\n",
    " 'overall_time_min_na',\n",
    " 'update2create_time_min_na',\n",
    " 'send2update_time_min_na',\n",
    " 'overall_time_max_na',\n",
    " 'update2create_time_max_na',\n",
    " 'send2update_time_max_na',\n",
    " 'dummy_log_lastgap',\n",
    " 'dummy_log_avg_gap',\n",
    " 'dummy_log_min_gap',\n",
    " 'dummy_log_max_gap',\n",
    " 'dummy_log_update2create_time_mean',\n",
    " 'dummy_log_send2update_time_mean',\n",
    " 'dummy_log_update2create_time_min',\n",
    " 'dummy_log_send2update_time_min',\n",
    " 'dummy_log_update2create_time_max',\n",
    " 'dummy_log_send2update_time_max',                               \n",
    " 'staple_price',                         \n",
    " 'like_num',                                                                                                                                                \n",
    " 'dummy_like_num',                   \n",
    " 'dummy_star',                        \n",
    " 'dummy_has_kitchen_info',\n",
    " 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to re-use data, remember to set free_raw_data=False\n",
    "lgb_train = lgb.Dataset(X_train, y_train,\\\n",
    "                        free_raw_data=False)\n",
    "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train,\n",
    "                       free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'max_depth':-1,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators':600,\n",
    "    'objective': 'binary',\n",
    "    'silent':False,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.587173\n",
      "[2]\ttraining's binary_logloss: 0.570298\n",
      "[3]\ttraining's binary_logloss: 0.555301\n",
      "[4]\ttraining's binary_logloss: 0.541822\n",
      "[5]\ttraining's binary_logloss: 0.529688\n",
      "[6]\ttraining's binary_logloss: 0.518708\n",
      "[7]\ttraining's binary_logloss: 0.508687\n",
      "[8]\ttraining's binary_logloss: 0.49957\n",
      "[9]\ttraining's binary_logloss: 0.491185\n",
      "[10]\ttraining's binary_logloss: 0.483536\n",
      "[11]\ttraining's binary_logloss: 0.476485\n",
      "[12]\ttraining's binary_logloss: 0.470021\n",
      "[13]\ttraining's binary_logloss: 0.464056\n",
      "[14]\ttraining's binary_logloss: 0.45858\n",
      "[15]\ttraining's binary_logloss: 0.45351\n",
      "[16]\ttraining's binary_logloss: 0.448822\n",
      "[17]\ttraining's binary_logloss: 0.444483\n",
      "[18]\ttraining's binary_logloss: 0.440423\n",
      "[19]\ttraining's binary_logloss: 0.436687\n",
      "[20]\ttraining's binary_logloss: 0.433207\n",
      "[21]\ttraining's binary_logloss: 0.429995\n",
      "[22]\ttraining's binary_logloss: 0.426996\n",
      "[23]\ttraining's binary_logloss: 0.424224\n",
      "[24]\ttraining's binary_logloss: 0.421638\n",
      "[25]\ttraining's binary_logloss: 0.419234\n",
      "[26]\ttraining's binary_logloss: 0.416996\n",
      "[27]\ttraining's binary_logloss: 0.414906\n",
      "[28]\ttraining's binary_logloss: 0.412951\n",
      "[29]\ttraining's binary_logloss: 0.411126\n",
      "[30]\ttraining's binary_logloss: 0.409408\n",
      "[31]\ttraining's binary_logloss: 0.407812\n",
      "[32]\ttraining's binary_logloss: 0.406336\n",
      "[33]\ttraining's binary_logloss: 0.404908\n",
      "[34]\ttraining's binary_logloss: 0.403618\n",
      "[35]\ttraining's binary_logloss: 0.4024\n",
      "[36]\ttraining's binary_logloss: 0.401258\n",
      "[37]\ttraining's binary_logloss: 0.400198\n",
      "[38]\ttraining's binary_logloss: 0.399223\n",
      "[39]\ttraining's binary_logloss: 0.398302\n",
      "[40]\ttraining's binary_logloss: 0.397417\n",
      "[41]\ttraining's binary_logloss: 0.396595\n",
      "[42]\ttraining's binary_logloss: 0.395819\n",
      "[43]\ttraining's binary_logloss: 0.395083\n",
      "[44]\ttraining's binary_logloss: 0.394383\n",
      "[45]\ttraining's binary_logloss: 0.393718\n",
      "[46]\ttraining's binary_logloss: 0.393111\n",
      "[47]\ttraining's binary_logloss: 0.392515\n",
      "[48]\ttraining's binary_logloss: 0.391957\n",
      "[49]\ttraining's binary_logloss: 0.391413\n",
      "[50]\ttraining's binary_logloss: 0.390916\n",
      "[51]\ttraining's binary_logloss: 0.39044\n",
      "[52]\ttraining's binary_logloss: 0.389998\n",
      "[53]\ttraining's binary_logloss: 0.389571\n",
      "[54]\ttraining's binary_logloss: 0.389175\n",
      "[55]\ttraining's binary_logloss: 0.38878\n",
      "[56]\ttraining's binary_logloss: 0.388423\n",
      "[57]\ttraining's binary_logloss: 0.388075\n",
      "[58]\ttraining's binary_logloss: 0.387734\n",
      "[59]\ttraining's binary_logloss: 0.387428\n",
      "[60]\ttraining's binary_logloss: 0.387128\n",
      "[61]\ttraining's binary_logloss: 0.386843\n",
      "[62]\ttraining's binary_logloss: 0.386558\n",
      "[63]\ttraining's binary_logloss: 0.386296\n",
      "[64]\ttraining's binary_logloss: 0.386045\n",
      "[65]\ttraining's binary_logloss: 0.385799\n",
      "[66]\ttraining's binary_logloss: 0.38557\n",
      "[67]\ttraining's binary_logloss: 0.385335\n",
      "[68]\ttraining's binary_logloss: 0.385112\n",
      "[69]\ttraining's binary_logloss: 0.384897\n",
      "[70]\ttraining's binary_logloss: 0.384692\n",
      "[71]\ttraining's binary_logloss: 0.384482\n",
      "[72]\ttraining's binary_logloss: 0.384295\n",
      "[73]\ttraining's binary_logloss: 0.384109\n",
      "[74]\ttraining's binary_logloss: 0.383932\n",
      "[75]\ttraining's binary_logloss: 0.383754\n",
      "[76]\ttraining's binary_logloss: 0.383581\n",
      "[77]\ttraining's binary_logloss: 0.383398\n",
      "[78]\ttraining's binary_logloss: 0.383242\n",
      "[79]\ttraining's binary_logloss: 0.383058\n",
      "[80]\ttraining's binary_logloss: 0.382902\n",
      "[81]\ttraining's binary_logloss: 0.382758\n",
      "[82]\ttraining's binary_logloss: 0.382614\n",
      "[83]\ttraining's binary_logloss: 0.382463\n",
      "[84]\ttraining's binary_logloss: 0.382308\n",
      "[85]\ttraining's binary_logloss: 0.382152\n",
      "[86]\ttraining's binary_logloss: 0.382012\n",
      "[87]\ttraining's binary_logloss: 0.381878\n",
      "[88]\ttraining's binary_logloss: 0.381734\n",
      "[89]\ttraining's binary_logloss: 0.38159\n",
      "[90]\ttraining's binary_logloss: 0.381462\n",
      "[91]\ttraining's binary_logloss: 0.381333\n",
      "[92]\ttraining's binary_logloss: 0.381204\n",
      "[93]\ttraining's binary_logloss: 0.381086\n",
      "[94]\ttraining's binary_logloss: 0.380967\n",
      "[95]\ttraining's binary_logloss: 0.380836\n",
      "[96]\ttraining's binary_logloss: 0.380706\n",
      "[97]\ttraining's binary_logloss: 0.380586\n",
      "[98]\ttraining's binary_logloss: 0.380471\n",
      "[99]\ttraining's binary_logloss: 0.380365\n",
      "[100]\ttraining's binary_logloss: 0.380252\n",
      "[101]\ttraining's binary_logloss: 0.380138\n",
      "[102]\ttraining's binary_logloss: 0.380011\n",
      "[103]\ttraining's binary_logloss: 0.3799\n",
      "[104]\ttraining's binary_logloss: 0.379773\n",
      "[105]\ttraining's binary_logloss: 0.379663\n",
      "[106]\ttraining's binary_logloss: 0.379554\n",
      "[107]\ttraining's binary_logloss: 0.379449\n",
      "[108]\ttraining's binary_logloss: 0.379327\n",
      "[109]\ttraining's binary_logloss: 0.379216\n",
      "[110]\ttraining's binary_logloss: 0.379109\n",
      "[111]\ttraining's binary_logloss: 0.379\n",
      "[112]\ttraining's binary_logloss: 0.378898\n",
      "[113]\ttraining's binary_logloss: 0.378783\n",
      "[114]\ttraining's binary_logloss: 0.378664\n",
      "[115]\ttraining's binary_logloss: 0.378562\n",
      "[116]\ttraining's binary_logloss: 0.378455\n",
      "[117]\ttraining's binary_logloss: 0.378356\n",
      "[118]\ttraining's binary_logloss: 0.378252\n",
      "[119]\ttraining's binary_logloss: 0.37814\n",
      "[120]\ttraining's binary_logloss: 0.378038\n",
      "[121]\ttraining's binary_logloss: 0.377933\n",
      "[122]\ttraining's binary_logloss: 0.377841\n",
      "[123]\ttraining's binary_logloss: 0.377729\n",
      "[124]\ttraining's binary_logloss: 0.377626\n",
      "[125]\ttraining's binary_logloss: 0.377542\n",
      "[126]\ttraining's binary_logloss: 0.377427\n",
      "[127]\ttraining's binary_logloss: 0.377324\n",
      "[128]\ttraining's binary_logloss: 0.377234\n",
      "[129]\ttraining's binary_logloss: 0.377128\n",
      "[130]\ttraining's binary_logloss: 0.377021\n",
      "[131]\ttraining's binary_logloss: 0.376927\n",
      "[132]\ttraining's binary_logloss: 0.376827\n",
      "[133]\ttraining's binary_logloss: 0.376731\n",
      "[134]\ttraining's binary_logloss: 0.376649\n",
      "[135]\ttraining's binary_logloss: 0.376547\n",
      "[136]\ttraining's binary_logloss: 0.37646\n",
      "[137]\ttraining's binary_logloss: 0.376358\n",
      "[138]\ttraining's binary_logloss: 0.376269\n",
      "[139]\ttraining's binary_logloss: 0.376171\n",
      "[140]\ttraining's binary_logloss: 0.376071\n",
      "[141]\ttraining's binary_logloss: 0.375969\n",
      "[142]\ttraining's binary_logloss: 0.37586\n",
      "[143]\ttraining's binary_logloss: 0.375755\n",
      "[144]\ttraining's binary_logloss: 0.375653\n",
      "[145]\ttraining's binary_logloss: 0.375556\n",
      "[146]\ttraining's binary_logloss: 0.37547\n",
      "[147]\ttraining's binary_logloss: 0.375379\n",
      "[148]\ttraining's binary_logloss: 0.375295\n",
      "[149]\ttraining's binary_logloss: 0.375194\n",
      "[150]\ttraining's binary_logloss: 0.375105\n",
      "[151]\ttraining's binary_logloss: 0.375022\n",
      "[152]\ttraining's binary_logloss: 0.374949\n",
      "[153]\ttraining's binary_logloss: 0.374859\n",
      "[154]\ttraining's binary_logloss: 0.374777\n",
      "[155]\ttraining's binary_logloss: 0.374708\n",
      "[156]\ttraining's binary_logloss: 0.374604\n",
      "[157]\ttraining's binary_logloss: 0.374512\n",
      "[158]\ttraining's binary_logloss: 0.374423\n",
      "[159]\ttraining's binary_logloss: 0.374338\n",
      "[160]\ttraining's binary_logloss: 0.374258\n",
      "[161]\ttraining's binary_logloss: 0.374173\n",
      "[162]\ttraining's binary_logloss: 0.374078\n",
      "[163]\ttraining's binary_logloss: 0.373992\n",
      "[164]\ttraining's binary_logloss: 0.373903\n",
      "[165]\ttraining's binary_logloss: 0.373816\n",
      "[166]\ttraining's binary_logloss: 0.37372\n",
      "[167]\ttraining's binary_logloss: 0.373651\n",
      "[168]\ttraining's binary_logloss: 0.373589\n",
      "[169]\ttraining's binary_logloss: 0.37352\n",
      "[170]\ttraining's binary_logloss: 0.373441\n",
      "[171]\ttraining's binary_logloss: 0.373363\n",
      "[172]\ttraining's binary_logloss: 0.373275\n",
      "[173]\ttraining's binary_logloss: 0.373179\n",
      "[174]\ttraining's binary_logloss: 0.373091\n",
      "[175]\ttraining's binary_logloss: 0.373002\n",
      "[176]\ttraining's binary_logloss: 0.37292\n",
      "[177]\ttraining's binary_logloss: 0.372844\n",
      "[178]\ttraining's binary_logloss: 0.372759\n",
      "[179]\ttraining's binary_logloss: 0.372666\n",
      "[180]\ttraining's binary_logloss: 0.372575\n",
      "[181]\ttraining's binary_logloss: 0.372524\n",
      "[182]\ttraining's binary_logloss: 0.372463\n",
      "[183]\ttraining's binary_logloss: 0.372376\n",
      "[184]\ttraining's binary_logloss: 0.372284\n",
      "[185]\ttraining's binary_logloss: 0.372192\n",
      "[186]\ttraining's binary_logloss: 0.372116\n",
      "[187]\ttraining's binary_logloss: 0.372038\n",
      "[188]\ttraining's binary_logloss: 0.371942\n",
      "[189]\ttraining's binary_logloss: 0.371843\n",
      "[190]\ttraining's binary_logloss: 0.37175\n",
      "[191]\ttraining's binary_logloss: 0.37166\n",
      "[192]\ttraining's binary_logloss: 0.37159\n",
      "[193]\ttraining's binary_logloss: 0.371506\n",
      "[194]\ttraining's binary_logloss: 0.371422\n",
      "[195]\ttraining's binary_logloss: 0.371335\n",
      "[196]\ttraining's binary_logloss: 0.37126\n",
      "[197]\ttraining's binary_logloss: 0.371163\n",
      "[198]\ttraining's binary_logloss: 0.371082\n",
      "[199]\ttraining's binary_logloss: 0.370994\n",
      "[200]\ttraining's binary_logloss: 0.370914\n",
      "[201]\ttraining's binary_logloss: 0.370838\n",
      "[202]\ttraining's binary_logloss: 0.370746\n",
      "[203]\ttraining's binary_logloss: 0.370694\n",
      "[204]\ttraining's binary_logloss: 0.370613\n",
      "[205]\ttraining's binary_logloss: 0.370527\n",
      "[206]\ttraining's binary_logloss: 0.370451\n",
      "[207]\ttraining's binary_logloss: 0.370357\n",
      "[208]\ttraining's binary_logloss: 0.370277\n",
      "[209]\ttraining's binary_logloss: 0.370211\n",
      "[210]\ttraining's binary_logloss: 0.370149\n",
      "[211]\ttraining's binary_logloss: 0.370077\n",
      "[212]\ttraining's binary_logloss: 0.370009\n",
      "[213]\ttraining's binary_logloss: 0.36993\n",
      "[214]\ttraining's binary_logloss: 0.36983\n",
      "[215]\ttraining's binary_logloss: 0.369753\n",
      "[216]\ttraining's binary_logloss: 0.369697\n",
      "[217]\ttraining's binary_logloss: 0.369629\n",
      "[218]\ttraining's binary_logloss: 0.369542\n",
      "[219]\ttraining's binary_logloss: 0.369467\n",
      "[220]\ttraining's binary_logloss: 0.369389\n",
      "[221]\ttraining's binary_logloss: 0.369313\n",
      "[222]\ttraining's binary_logloss: 0.369245\n",
      "[223]\ttraining's binary_logloss: 0.369167\n",
      "[224]\ttraining's binary_logloss: 0.369083\n",
      "[225]\ttraining's binary_logloss: 0.369002\n",
      "[226]\ttraining's binary_logloss: 0.36891\n",
      "[227]\ttraining's binary_logloss: 0.368824\n",
      "[228]\ttraining's binary_logloss: 0.368738\n",
      "[229]\ttraining's binary_logloss: 0.368693\n",
      "[230]\ttraining's binary_logloss: 0.368607\n",
      "[231]\ttraining's binary_logloss: 0.368519\n",
      "[232]\ttraining's binary_logloss: 0.368457\n",
      "[233]\ttraining's binary_logloss: 0.368379\n",
      "[234]\ttraining's binary_logloss: 0.368298\n",
      "[235]\ttraining's binary_logloss: 0.36822\n",
      "[236]\ttraining's binary_logloss: 0.368142\n",
      "[237]\ttraining's binary_logloss: 0.368066\n",
      "[238]\ttraining's binary_logloss: 0.367997\n",
      "[239]\ttraining's binary_logloss: 0.367918\n",
      "[240]\ttraining's binary_logloss: 0.367831\n",
      "[241]\ttraining's binary_logloss: 0.367755\n",
      "[242]\ttraining's binary_logloss: 0.367663\n",
      "[243]\ttraining's binary_logloss: 0.367623\n",
      "[244]\ttraining's binary_logloss: 0.367537\n",
      "[245]\ttraining's binary_logloss: 0.367468\n",
      "[246]\ttraining's binary_logloss: 0.367394\n",
      "[247]\ttraining's binary_logloss: 0.367316\n",
      "[248]\ttraining's binary_logloss: 0.367238\n",
      "[249]\ttraining's binary_logloss: 0.367148\n",
      "[250]\ttraining's binary_logloss: 0.367066\n",
      "[251]\ttraining's binary_logloss: 0.366989\n",
      "[252]\ttraining's binary_logloss: 0.366919\n",
      "[253]\ttraining's binary_logloss: 0.366847\n",
      "[254]\ttraining's binary_logloss: 0.366791\n",
      "[255]\ttraining's binary_logloss: 0.366712\n",
      "[256]\ttraining's binary_logloss: 0.36666\n",
      "[257]\ttraining's binary_logloss: 0.3666\n",
      "[258]\ttraining's binary_logloss: 0.366509\n",
      "[259]\ttraining's binary_logloss: 0.366441\n",
      "[260]\ttraining's binary_logloss: 0.36635\n",
      "[261]\ttraining's binary_logloss: 0.366267\n",
      "[262]\ttraining's binary_logloss: 0.366212\n",
      "[263]\ttraining's binary_logloss: 0.36613\n",
      "[264]\ttraining's binary_logloss: 0.366048\n",
      "[265]\ttraining's binary_logloss: 0.365982\n",
      "[266]\ttraining's binary_logloss: 0.365898\n",
      "[267]\ttraining's binary_logloss: 0.365816\n",
      "[268]\ttraining's binary_logloss: 0.365722\n",
      "[269]\ttraining's binary_logloss: 0.365648\n",
      "[270]\ttraining's binary_logloss: 0.365581\n",
      "[271]\ttraining's binary_logloss: 0.365513\n",
      "[272]\ttraining's binary_logloss: 0.365442\n",
      "[273]\ttraining's binary_logloss: 0.365379\n",
      "[274]\ttraining's binary_logloss: 0.365321\n",
      "[275]\ttraining's binary_logloss: 0.365248\n",
      "[276]\ttraining's binary_logloss: 0.36518\n",
      "[277]\ttraining's binary_logloss: 0.365105\n",
      "[278]\ttraining's binary_logloss: 0.365064\n",
      "[279]\ttraining's binary_logloss: 0.365014\n",
      "[280]\ttraining's binary_logloss: 0.364946\n",
      "[281]\ttraining's binary_logloss: 0.364873\n",
      "[282]\ttraining's binary_logloss: 0.36479\n",
      "[283]\ttraining's binary_logloss: 0.364726\n",
      "[284]\ttraining's binary_logloss: 0.364663\n",
      "[285]\ttraining's binary_logloss: 0.364588\n",
      "[286]\ttraining's binary_logloss: 0.364525\n",
      "[287]\ttraining's binary_logloss: 0.364449\n",
      "[288]\ttraining's binary_logloss: 0.364367\n",
      "[289]\ttraining's binary_logloss: 0.364283\n",
      "[290]\ttraining's binary_logloss: 0.364194\n",
      "[291]\ttraining's binary_logloss: 0.364118\n",
      "[292]\ttraining's binary_logloss: 0.364049\n",
      "[293]\ttraining's binary_logloss: 0.36396\n",
      "[294]\ttraining's binary_logloss: 0.363879\n",
      "[295]\ttraining's binary_logloss: 0.363832\n",
      "[296]\ttraining's binary_logloss: 0.363765\n",
      "[297]\ttraining's binary_logloss: 0.363696\n",
      "[298]\ttraining's binary_logloss: 0.363619\n",
      "[299]\ttraining's binary_logloss: 0.363559\n",
      "[300]\ttraining's binary_logloss: 0.363483\n",
      "[301]\ttraining's binary_logloss: 0.363443\n",
      "[302]\ttraining's binary_logloss: 0.36337\n",
      "[303]\ttraining's binary_logloss: 0.363287\n",
      "[304]\ttraining's binary_logloss: 0.363208\n",
      "[305]\ttraining's binary_logloss: 0.363155\n",
      "[306]\ttraining's binary_logloss: 0.363089\n",
      "[307]\ttraining's binary_logloss: 0.363037\n",
      "[308]\ttraining's binary_logloss: 0.36297\n",
      "[309]\ttraining's binary_logloss: 0.362886\n",
      "[310]\ttraining's binary_logloss: 0.362836\n",
      "[311]\ttraining's binary_logloss: 0.362762\n",
      "[312]\ttraining's binary_logloss: 0.362708\n",
      "[313]\ttraining's binary_logloss: 0.362623\n",
      "[314]\ttraining's binary_logloss: 0.362549\n",
      "[315]\ttraining's binary_logloss: 0.362477\n",
      "[316]\ttraining's binary_logloss: 0.36241\n",
      "[317]\ttraining's binary_logloss: 0.362327\n",
      "[318]\ttraining's binary_logloss: 0.362267\n",
      "[319]\ttraining's binary_logloss: 0.362192\n",
      "[320]\ttraining's binary_logloss: 0.362125\n",
      "[321]\ttraining's binary_logloss: 0.362074\n",
      "[322]\ttraining's binary_logloss: 0.362012\n",
      "[323]\ttraining's binary_logloss: 0.361934\n",
      "[324]\ttraining's binary_logloss: 0.361856\n",
      "[325]\ttraining's binary_logloss: 0.361776\n",
      "[326]\ttraining's binary_logloss: 0.361721\n",
      "[327]\ttraining's binary_logloss: 0.36167\n",
      "[328]\ttraining's binary_logloss: 0.361589\n",
      "[329]\ttraining's binary_logloss: 0.361506\n",
      "[330]\ttraining's binary_logloss: 0.361424\n",
      "[331]\ttraining's binary_logloss: 0.361371\n",
      "[332]\ttraining's binary_logloss: 0.361338\n",
      "[333]\ttraining's binary_logloss: 0.361249\n",
      "[334]\ttraining's binary_logloss: 0.361178\n",
      "[335]\ttraining's binary_logloss: 0.36111\n",
      "[336]\ttraining's binary_logloss: 0.36103\n",
      "[337]\ttraining's binary_logloss: 0.36095\n",
      "[338]\ttraining's binary_logloss: 0.360868\n",
      "[339]\ttraining's binary_logloss: 0.360793\n",
      "[340]\ttraining's binary_logloss: 0.360734\n",
      "[341]\ttraining's binary_logloss: 0.360654\n",
      "[342]\ttraining's binary_logloss: 0.360592\n",
      "[343]\ttraining's binary_logloss: 0.360527\n",
      "[344]\ttraining's binary_logloss: 0.360478\n",
      "[345]\ttraining's binary_logloss: 0.360409\n",
      "[346]\ttraining's binary_logloss: 0.36033\n",
      "[347]\ttraining's binary_logloss: 0.360269\n",
      "[348]\ttraining's binary_logloss: 0.360222\n",
      "[349]\ttraining's binary_logloss: 0.360169\n",
      "[350]\ttraining's binary_logloss: 0.360101\n",
      "[351]\ttraining's binary_logloss: 0.360059\n",
      "[352]\ttraining's binary_logloss: 0.360019\n",
      "[353]\ttraining's binary_logloss: 0.35994\n",
      "[354]\ttraining's binary_logloss: 0.35987\n",
      "[355]\ttraining's binary_logloss: 0.359809\n",
      "[356]\ttraining's binary_logloss: 0.359733\n",
      "[357]\ttraining's binary_logloss: 0.359671\n",
      "[358]\ttraining's binary_logloss: 0.359631\n",
      "[359]\ttraining's binary_logloss: 0.359555\n",
      "[360]\ttraining's binary_logloss: 0.359472\n",
      "[361]\ttraining's binary_logloss: 0.359387\n",
      "[362]\ttraining's binary_logloss: 0.359306\n",
      "[363]\ttraining's binary_logloss: 0.359229\n",
      "[364]\ttraining's binary_logloss: 0.359187\n",
      "[365]\ttraining's binary_logloss: 0.359147\n",
      "[366]\ttraining's binary_logloss: 0.359069\n",
      "[367]\ttraining's binary_logloss: 0.359006\n",
      "[368]\ttraining's binary_logloss: 0.358925\n",
      "[369]\ttraining's binary_logloss: 0.35888\n",
      "[370]\ttraining's binary_logloss: 0.3588\n",
      "[371]\ttraining's binary_logloss: 0.35874\n",
      "[372]\ttraining's binary_logloss: 0.358668\n",
      "[373]\ttraining's binary_logloss: 0.358592\n",
      "[374]\ttraining's binary_logloss: 0.358532\n",
      "[375]\ttraining's binary_logloss: 0.358462\n",
      "[376]\ttraining's binary_logloss: 0.358392\n",
      "[377]\ttraining's binary_logloss: 0.358338\n",
      "[378]\ttraining's binary_logloss: 0.358263\n",
      "[379]\ttraining's binary_logloss: 0.358192\n",
      "[380]\ttraining's binary_logloss: 0.358125\n",
      "[381]\ttraining's binary_logloss: 0.358056\n",
      "[382]\ttraining's binary_logloss: 0.357987\n",
      "[383]\ttraining's binary_logloss: 0.357918\n",
      "[384]\ttraining's binary_logloss: 0.357836\n",
      "[385]\ttraining's binary_logloss: 0.35779\n",
      "[386]\ttraining's binary_logloss: 0.357707\n",
      "[387]\ttraining's binary_logloss: 0.357667\n",
      "[388]\ttraining's binary_logloss: 0.357632\n",
      "[389]\ttraining's binary_logloss: 0.357559\n",
      "[390]\ttraining's binary_logloss: 0.357471\n",
      "[391]\ttraining's binary_logloss: 0.357423\n",
      "[392]\ttraining's binary_logloss: 0.357345\n",
      "[393]\ttraining's binary_logloss: 0.357272\n",
      "[394]\ttraining's binary_logloss: 0.357191\n",
      "[395]\ttraining's binary_logloss: 0.357121\n",
      "[396]\ttraining's binary_logloss: 0.357059\n",
      "[397]\ttraining's binary_logloss: 0.356987\n",
      "[398]\ttraining's binary_logloss: 0.356926\n",
      "[399]\ttraining's binary_logloss: 0.356883\n",
      "[400]\ttraining's binary_logloss: 0.356785\n",
      "[401]\ttraining's binary_logloss: 0.356715\n",
      "[402]\ttraining's binary_logloss: 0.356644\n",
      "[403]\ttraining's binary_logloss: 0.356571\n",
      "[404]\ttraining's binary_logloss: 0.356492\n",
      "[405]\ttraining's binary_logloss: 0.35641\n",
      "[406]\ttraining's binary_logloss: 0.356334\n",
      "[407]\ttraining's binary_logloss: 0.356264\n",
      "[408]\ttraining's binary_logloss: 0.356202\n",
      "[409]\ttraining's binary_logloss: 0.356132\n",
      "[410]\ttraining's binary_logloss: 0.356052\n",
      "[411]\ttraining's binary_logloss: 0.355991\n",
      "[412]\ttraining's binary_logloss: 0.355947\n",
      "[413]\ttraining's binary_logloss: 0.35586\n",
      "[414]\ttraining's binary_logloss: 0.355768\n",
      "[415]\ttraining's binary_logloss: 0.355693\n",
      "[416]\ttraining's binary_logloss: 0.355622\n",
      "[417]\ttraining's binary_logloss: 0.355549\n",
      "[418]\ttraining's binary_logloss: 0.355486\n",
      "[419]\ttraining's binary_logloss: 0.355437\n",
      "[420]\ttraining's binary_logloss: 0.355371\n",
      "[421]\ttraining's binary_logloss: 0.355298\n",
      "[422]\ttraining's binary_logloss: 0.355237\n",
      "[423]\ttraining's binary_logloss: 0.355197\n",
      "[424]\ttraining's binary_logloss: 0.355151\n",
      "[425]\ttraining's binary_logloss: 0.35507\n",
      "[426]\ttraining's binary_logloss: 0.354991\n",
      "[427]\ttraining's binary_logloss: 0.35492\n",
      "[428]\ttraining's binary_logloss: 0.354828\n",
      "[429]\ttraining's binary_logloss: 0.354744\n",
      "[430]\ttraining's binary_logloss: 0.354672\n",
      "[431]\ttraining's binary_logloss: 0.35461\n",
      "[432]\ttraining's binary_logloss: 0.35453\n",
      "[433]\ttraining's binary_logloss: 0.354453\n",
      "[434]\ttraining's binary_logloss: 0.354388\n",
      "[435]\ttraining's binary_logloss: 0.354314\n",
      "[436]\ttraining's binary_logloss: 0.354246\n",
      "[437]\ttraining's binary_logloss: 0.354183\n",
      "[438]\ttraining's binary_logloss: 0.354114\n",
      "[439]\ttraining's binary_logloss: 0.354037\n",
      "[440]\ttraining's binary_logloss: 0.353953\n",
      "[441]\ttraining's binary_logloss: 0.353886\n",
      "[442]\ttraining's binary_logloss: 0.353821\n",
      "[443]\ttraining's binary_logloss: 0.353767\n",
      "[444]\ttraining's binary_logloss: 0.353738\n",
      "[445]\ttraining's binary_logloss: 0.353682\n",
      "[446]\ttraining's binary_logloss: 0.353637\n",
      "[447]\ttraining's binary_logloss: 0.353563\n",
      "[448]\ttraining's binary_logloss: 0.35352\n",
      "[449]\ttraining's binary_logloss: 0.353441\n",
      "[450]\ttraining's binary_logloss: 0.353406\n",
      "[451]\ttraining's binary_logloss: 0.353356\n",
      "[452]\ttraining's binary_logloss: 0.353307\n",
      "[453]\ttraining's binary_logloss: 0.353227\n",
      "[454]\ttraining's binary_logloss: 0.353161\n",
      "[455]\ttraining's binary_logloss: 0.353096\n",
      "[456]\ttraining's binary_logloss: 0.353034\n",
      "[457]\ttraining's binary_logloss: 0.352946\n",
      "[458]\ttraining's binary_logloss: 0.352871\n",
      "[459]\ttraining's binary_logloss: 0.352814\n",
      "[460]\ttraining's binary_logloss: 0.352745\n",
      "[461]\ttraining's binary_logloss: 0.352678\n",
      "[462]\ttraining's binary_logloss: 0.352631\n",
      "[463]\ttraining's binary_logloss: 0.35257\n",
      "[464]\ttraining's binary_logloss: 0.3525\n",
      "[465]\ttraining's binary_logloss: 0.352435\n",
      "[466]\ttraining's binary_logloss: 0.352371\n",
      "[467]\ttraining's binary_logloss: 0.352282\n",
      "[468]\ttraining's binary_logloss: 0.352198\n",
      "[469]\ttraining's binary_logloss: 0.352126\n",
      "[470]\ttraining's binary_logloss: 0.352056\n",
      "[471]\ttraining's binary_logloss: 0.352014\n",
      "[472]\ttraining's binary_logloss: 0.351971\n",
      "[473]\ttraining's binary_logloss: 0.351895\n",
      "[474]\ttraining's binary_logloss: 0.35184\n",
      "[475]\ttraining's binary_logloss: 0.351773\n",
      "[476]\ttraining's binary_logloss: 0.351718\n",
      "[477]\ttraining's binary_logloss: 0.351653\n",
      "[478]\ttraining's binary_logloss: 0.351598\n",
      "[479]\ttraining's binary_logloss: 0.351524\n",
      "[480]\ttraining's binary_logloss: 0.351478\n",
      "[481]\ttraining's binary_logloss: 0.351406\n",
      "[482]\ttraining's binary_logloss: 0.351345\n",
      "[483]\ttraining's binary_logloss: 0.35127\n",
      "[484]\ttraining's binary_logloss: 0.351214\n",
      "[485]\ttraining's binary_logloss: 0.351168\n",
      "[486]\ttraining's binary_logloss: 0.351121\n",
      "[487]\ttraining's binary_logloss: 0.351061\n",
      "[488]\ttraining's binary_logloss: 0.350993\n",
      "[489]\ttraining's binary_logloss: 0.350936\n",
      "[490]\ttraining's binary_logloss: 0.350903\n",
      "[491]\ttraining's binary_logloss: 0.350849\n",
      "[492]\ttraining's binary_logloss: 0.35081\n",
      "[493]\ttraining's binary_logloss: 0.350745\n",
      "[494]\ttraining's binary_logloss: 0.350671\n",
      "[495]\ttraining's binary_logloss: 0.350595\n",
      "[496]\ttraining's binary_logloss: 0.350532\n",
      "[497]\ttraining's binary_logloss: 0.350461\n",
      "[498]\ttraining's binary_logloss: 0.350389\n",
      "[499]\ttraining's binary_logloss: 0.35031\n",
      "[500]\ttraining's binary_logloss: 0.350242\n",
      "[501]\ttraining's binary_logloss: 0.350175\n",
      "[502]\ttraining's binary_logloss: 0.35013\n",
      "[503]\ttraining's binary_logloss: 0.350104\n",
      "[504]\ttraining's binary_logloss: 0.350018\n",
      "[505]\ttraining's binary_logloss: 0.34998\n",
      "[506]\ttraining's binary_logloss: 0.349915\n",
      "[507]\ttraining's binary_logloss: 0.349857\n",
      "[508]\ttraining's binary_logloss: 0.349798\n",
      "[509]\ttraining's binary_logloss: 0.349735\n",
      "[510]\ttraining's binary_logloss: 0.349673\n",
      "[511]\ttraining's binary_logloss: 0.3496\n",
      "[512]\ttraining's binary_logloss: 0.349529\n",
      "[513]\ttraining's binary_logloss: 0.349456\n",
      "[514]\ttraining's binary_logloss: 0.349406\n",
      "[515]\ttraining's binary_logloss: 0.349355\n",
      "[516]\ttraining's binary_logloss: 0.349292\n",
      "[517]\ttraining's binary_logloss: 0.349243\n",
      "[518]\ttraining's binary_logloss: 0.349176\n",
      "[519]\ttraining's binary_logloss: 0.349105\n",
      "[520]\ttraining's binary_logloss: 0.349022\n",
      "[521]\ttraining's binary_logloss: 0.348958\n",
      "[522]\ttraining's binary_logloss: 0.348903\n",
      "[523]\ttraining's binary_logloss: 0.348861\n",
      "[524]\ttraining's binary_logloss: 0.348801\n",
      "[525]\ttraining's binary_logloss: 0.348736\n",
      "[526]\ttraining's binary_logloss: 0.34867\n",
      "[527]\ttraining's binary_logloss: 0.348588\n",
      "[528]\ttraining's binary_logloss: 0.348522\n",
      "[529]\ttraining's binary_logloss: 0.34848\n",
      "[530]\ttraining's binary_logloss: 0.348424\n",
      "[531]\ttraining's binary_logloss: 0.348363\n",
      "[532]\ttraining's binary_logloss: 0.348312\n",
      "[533]\ttraining's binary_logloss: 0.34826\n",
      "[534]\ttraining's binary_logloss: 0.348216\n",
      "[535]\ttraining's binary_logloss: 0.34815\n",
      "[536]\ttraining's binary_logloss: 0.348102\n",
      "[537]\ttraining's binary_logloss: 0.348027\n",
      "[538]\ttraining's binary_logloss: 0.347951\n",
      "[539]\ttraining's binary_logloss: 0.347908\n",
      "[540]\ttraining's binary_logloss: 0.347853\n",
      "[541]\ttraining's binary_logloss: 0.347786\n",
      "[542]\ttraining's binary_logloss: 0.347723\n",
      "[543]\ttraining's binary_logloss: 0.34766\n",
      "[544]\ttraining's binary_logloss: 0.347592\n",
      "[545]\ttraining's binary_logloss: 0.347529\n",
      "[546]\ttraining's binary_logloss: 0.347479\n",
      "[547]\ttraining's binary_logloss: 0.347421\n",
      "[548]\ttraining's binary_logloss: 0.347354\n",
      "[549]\ttraining's binary_logloss: 0.347302\n",
      "[550]\ttraining's binary_logloss: 0.347227\n",
      "[551]\ttraining's binary_logloss: 0.347158\n",
      "[552]\ttraining's binary_logloss: 0.347092\n",
      "[553]\ttraining's binary_logloss: 0.347036\n",
      "[554]\ttraining's binary_logloss: 0.346995\n",
      "[555]\ttraining's binary_logloss: 0.346927\n",
      "[556]\ttraining's binary_logloss: 0.34687\n",
      "[557]\ttraining's binary_logloss: 0.346808\n",
      "[558]\ttraining's binary_logloss: 0.346749\n",
      "[559]\ttraining's binary_logloss: 0.346681\n",
      "[560]\ttraining's binary_logloss: 0.34662\n",
      "[561]\ttraining's binary_logloss: 0.34656\n",
      "[562]\ttraining's binary_logloss: 0.346504\n",
      "[563]\ttraining's binary_logloss: 0.346431\n",
      "[564]\ttraining's binary_logloss: 0.346382\n",
      "[565]\ttraining's binary_logloss: 0.346326\n",
      "[566]\ttraining's binary_logloss: 0.346283\n",
      "[567]\ttraining's binary_logloss: 0.346241\n",
      "[568]\ttraining's binary_logloss: 0.346159\n",
      "[569]\ttraining's binary_logloss: 0.3461\n",
      "[570]\ttraining's binary_logloss: 0.346032\n",
      "[571]\ttraining's binary_logloss: 0.345994\n",
      "[572]\ttraining's binary_logloss: 0.345954\n",
      "[573]\ttraining's binary_logloss: 0.345902\n",
      "[574]\ttraining's binary_logloss: 0.345844\n",
      "[575]\ttraining's binary_logloss: 0.345813\n",
      "[576]\ttraining's binary_logloss: 0.345771\n",
      "[577]\ttraining's binary_logloss: 0.345718\n",
      "[578]\ttraining's binary_logloss: 0.34568\n",
      "[579]\ttraining's binary_logloss: 0.345607\n",
      "[580]\ttraining's binary_logloss: 0.345533\n",
      "[581]\ttraining's binary_logloss: 0.345472\n",
      "[582]\ttraining's binary_logloss: 0.345395\n",
      "[583]\ttraining's binary_logloss: 0.34533\n",
      "[584]\ttraining's binary_logloss: 0.345254\n",
      "[585]\ttraining's binary_logloss: 0.345172\n",
      "[586]\ttraining's binary_logloss: 0.345117\n",
      "[587]\ttraining's binary_logloss: 0.345066\n",
      "[588]\ttraining's binary_logloss: 0.345038\n",
      "[589]\ttraining's binary_logloss: 0.344974\n",
      "[590]\ttraining's binary_logloss: 0.344935\n",
      "[591]\ttraining's binary_logloss: 0.344896\n",
      "[592]\ttraining's binary_logloss: 0.344829\n",
      "[593]\ttraining's binary_logloss: 0.344747\n",
      "[594]\ttraining's binary_logloss: 0.344704\n",
      "[595]\ttraining's binary_logloss: 0.344642\n",
      "[596]\ttraining's binary_logloss: 0.344616\n",
      "[597]\ttraining's binary_logloss: 0.344567\n",
      "[598]\ttraining's binary_logloss: 0.344532\n",
      "[599]\ttraining's binary_logloss: 0.344466\n",
      "[600]\ttraining's binary_logloss: 0.344388\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                valid_sets=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=gbm.predict(X_train)\n",
    "test_predict=gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds2 = roc_curve(y_test,test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'ROC curve')"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, color='darkorange',label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy',linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054103256343892"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train,train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770016477854039"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_classifier=lgb.LGBMClassifier(learning_rate=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.07, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_1=gbm_classifier.predict(X_train)\n",
    "test_predict_1=gbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88    108250\n",
      "         1.0       0.77      0.61      0.68     45234\n",
      "\n",
      "   micro avg       0.83      0.83      0.83    153484\n",
      "   macro avg       0.81      0.77      0.78    153484\n",
      "weighted avg       0.83      0.83      0.83    153484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, train_predict_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.91      0.88     27008\n",
      "         1.0       0.75      0.61      0.68     11363\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     38371\n",
      "   macro avg       0.80      0.76      0.78     38371\n",
      "weighted avg       0.82      0.83      0.82     38371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predict_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_1_=gbm_classifier.predict_proba(X_train)\n",
    "test_predict_1_=gbm_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840888284181174"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,train_predict_1_.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772566105230328"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,test_predict_1_.T[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e5608d0>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resident plot\n",
    "sns.scatterplot(x=y_train, y=(train_predict_1_.T[1]-y_train),alpha=0.2,marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['residual']=y_train-train_predict_1_.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1=X_train[X_train['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45234.000000\n",
       "mean         0.411707\n",
       "std          0.286631\n",
       "min          0.006417\n",
       "25%          0.152203\n",
       "50%          0.373989\n",
       "75%          0.661091\n",
       "max          0.994164\n",
       "Name: residual, dtype: float64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1['residual'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34725"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_1[(X_train_1['residual']>(1-3*0.286607)) \\\n",
    "              & (X_train_1['residual']<(1+3*0.286607))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0=X_train[X_train['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    108250.000000\n",
       "mean         -0.172057\n",
       "std           0.186016\n",
       "min          -0.982729\n",
       "25%          -0.238195\n",
       "50%          -0.101305\n",
       "75%          -0.038574\n",
       "max          -0.005256\n",
       "Name: residual, dtype: float64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0['residual'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106026"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_0[(X_train_0['residual']>(0-4*0.184737)) \\\n",
    "              & (X_train_0['residual']<(0+4*0.184737))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=X_train_1\n",
    "# train_1=X_train_1[(X_train_1['residual']>(1-3*0.286607)) \\\n",
    "#               & (X_train_1['residual']<(1+3*0.286607))]\n",
    "train_0=X_train_0[(X_train_0['residual']>(0-4*0.184737)) \\\n",
    "              & (X_train_0['residual']<(0+4*0.184737))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trian_all=pd.concat([train_0,train_1], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=X_trian_all['label']\n",
    "X_train=X_trian_all.drop(['residual','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_classifier=lgb.LGBMClassifier(num_leaves=20,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=20, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_2=gbm_classifier.predict(X_train)\n",
    "test_predict_2=gbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89    106026\n",
      "         1.0       0.82      0.61      0.70     45234\n",
      "\n",
      "   micro avg       0.84      0.84      0.84    151260\n",
      "   macro avg       0.83      0.78      0.80    151260\n",
      "weighted avg       0.84      0.84      0.84    151260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, train_predict_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88     27008\n",
      "         1.0       0.75      0.61      0.67     11363\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     38371\n",
      "   macro avg       0.80      0.76      0.78     38371\n",
      "weighted avg       0.82      0.83      0.82     38371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predict_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_2_=gbm_classifier.predict_proba(X_train)\n",
    "test_predict_2_=gbm_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956890310764684"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,train_predict_2_.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771816557923926"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,test_predict_2_.T[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label']=y_train\n",
    "bag = X_train[X_train['label']==1]\n",
    "boot = resample(bag, replace=True, n_samples=int(len(X_train[X_train['label']==0])*0.2), random_state=1)\n",
    "X_train=pd.concat([boot,X_train],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=X_train['label']\n",
    "X_train=X_train.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_3=gbm_classifier.predict(X_train)\n",
    "test_predict_3=gbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.94      0.88    101950\n",
      "         1.0       0.88      0.70      0.78     65624\n",
      "\n",
      "   micro avg       0.84      0.84      0.84    167574\n",
      "   macro avg       0.85      0.82      0.83    167574\n",
      "weighted avg       0.85      0.84      0.84    167574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, train_predict_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87     27008\n",
      "         1.0       0.70      0.69      0.69     11363\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     38371\n",
      "   macro avg       0.78      0.78      0.78     38371\n",
      "weighted avg       0.82      0.82      0.82     38371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predict_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_3_=gbm_classifier.predict_proba(X_train)\n",
    "test_predict_3_=gbm_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085824414858542"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,train_predict_3_.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764028310763128"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,test_predict_3_.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_predict_2_.T[1]).to_csv('lightgbm_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_predict_2_.T[1]).to_csv('lightgbm_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=pd.Series(gbm_classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=pd.Series(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>log_last_order</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>app_version_b</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>w7_total_orders</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active_days</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>login_platform_b</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>age</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>log_w7_total_orders</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>accountLength</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>last_coupon_fee</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>last_order</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w6_total_orders</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>log_avg_gap</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>log_intime_rate</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pca_2</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>log_last_coupon_fee</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w5_total_orders</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>log_w6_total_orders</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sex</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pca_4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>pca_5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>overall_time_min</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>log_w7_max_couponworth</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>log_accountLength</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pca_1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>w7_avg_couponworth</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>log_first_order</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>update2create_time_min</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>pca_3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>overall_time_max</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>log_w5_total_orders</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0    1\n",
       "77           log_last_order  216\n",
       "32            app_version_b  191\n",
       "12          w7_total_orders  149\n",
       "1               active_days  122\n",
       "31         login_platform_b   95\n",
       "30                      age   83\n",
       "75      log_w7_total_orders   80\n",
       "15            accountLength   78\n",
       "25          last_coupon_fee   77\n",
       "14               last_order   74\n",
       "11          w6_total_orders   71\n",
       "102             log_avg_gap   63\n",
       "82          log_intime_rate   58\n",
       "48                    pca_2   56\n",
       "83      log_last_coupon_fee   55\n",
       "10          w5_total_orders   51\n",
       "74      log_w6_total_orders   48\n",
       "29                      sex   47\n",
       "50                    pca_4   45\n",
       "51                    pca_5   45\n",
       "19         overall_time_min   40\n",
       "98   log_w7_max_couponworth   38\n",
       "78        log_accountLength   35\n",
       "47                    pca_1   35\n",
       "58       w7_avg_couponworth   33\n",
       "76          log_first_order   33\n",
       "20   update2create_time_min   32\n",
       "49                    pca_3   31\n",
       "22         overall_time_max   31\n",
       "73      log_w5_total_orders   30"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([columns,importances],axis=1).sort_values(by=1,ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
